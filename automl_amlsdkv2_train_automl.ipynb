{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Customer Churn Prediction using Automated ML in Azure Machine Learning using Azure ML SDK V2\n",
    "\n",
    "This notebook guides users to create an Automl job using AML SDK V2. Once the AutoML job completes, the best performing model is registered in AML registry using MLFLow. \n",
    "\n",
    "\n",
    "This notebook uses [Telco Customer Churn data from IBM Sample Datasets](https://community.ibm.com/community/user/businessanalytics/blogs/steven-macko/2019/07/11/telco-customer-churn-1113).\n",
    "\n",
    "\n",
    "### Pre-requisites\n",
    "* Azure Machine Learning workspace provisioned.\n",
    "* Compute Cluster provisioned in the workspace.\n",
    "* Training Cluster created. Recommend to create training cluster with 3 nodes with each Node have 2 vCPUs. This can reduce the AutoML training time. This notebook takes about 12 minutes to complete the training on a 3 node CPU cluster with Standard_DS11_v2 (2 cores, 14 GB RAM, 28 GB disk). \n",
    "* Recommendation is to use AML compute instance to run the notebook.\n",
    "* The notebook can be run locally but will the following dependencies installed locally:\n",
    " \n",
    "    - python installed - python 3.8+\n",
    "    - conda installed\n",
    "    - Azure ML Python [SDK](https://learn.microsoft.com/en-us/python/api/overview/azure/ai-ml-readme?view=azure-python) and [CLI](https://learn.microsoft.com/en-us/azure/machine-learning/how-to-configure-cli?view=azureml-api-2&tabs=public) v2 installed.\n",
    "    - Install additional dependencies in the conda_env.yml\n",
    "    \n",
    "            conda env create -f conda_env.yml\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "* AML workspace can be configured with Private Endpoint and necessary DNS changes are made as documented [here](https://learn.microsoft.com/en-us/azure/machine-learning/how-to-custom-dns?view=azureml-api-2&tabs=azure-cli). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Login using Azure using az login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.identity import DefaultAzureCredential, InteractiveBrowserCredential\n",
    "from azure.ai.ml import MLClient\n",
    "try:\n",
    "    credential = DefaultAzureCredential()\n",
    "    # Check if given credential can get token successfully.\n",
    "    credential.get_token(\"https://management.azure.com/.default\")\n",
    "except Exception as ex:\n",
    "    # Fall back to InteractiveBrowserCredential in case DefaultAzureCredential not work\n",
    "    credential = InteractiveBrowserCredential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Provide values for your AML workspace\n",
    "\n",
    "    subscription_id = \"YOUR_SUBSCRIPTION_ID\"\n",
    "    resource_group = \"YOUR_RESOURCE_GROUP\"\n",
    "    workspace = \"YOUR_WORKSPACE_NAME\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ml_client = None\n",
    "try:\n",
    "    ml_client = MLClient.from_config(credential)\n",
    "except Exception as ex:\n",
    "    print(ex)\n",
    "    # Enter details of your Azure Machine Learning workspace\n",
    "    subscription_id = \"f1a8fafd-a8a3-46d8-bb5e-01deb63d275d\"\n",
    "    resource_group = \"aml-rg\"\n",
    "    workspace = \"aml-testws\"\n",
    "    ml_client = MLClient(credential, subscription_id, resource_group, workspace)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the Sample Dataset WA_Fn-UseC_-Telco-Customer-Churn.csv and create datasets for Training and Testing. \n",
    "The test dataset is used to create a scoring job using the best performance model. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load training data from CSV file\n",
    "training_data = pd.read_csv('./telcocustomerchurn/WA_Fn-UseC_-Telco-Customer-Churn.csv')\n",
    "\n",
    "# Separate the data into features (X) and labels (y)\n",
    "X = training_data.drop(columns=['Churn'])  # Assuming 'label' is the column containing class labels\n",
    "y = training_data['Churn']\n",
    "\n",
    "# Split the data into training and test sets while maintaining class balance\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
    "\n",
    "# Combine the features and labels for training and test sets\n",
    "train_data = pd.concat([X_train, y_train], axis=1)\n",
    "test_data = pd.concat([X_test, y_test], axis=1)\n",
    "\n",
    "# Save the generated test data to a new CSV file\n",
    "test_data.to_csv('./telcocustomerchurn/WA_Fn-UseC_-Telco-Customer-Churn_Test.csv', index=False)\n",
    "\n",
    "# Save the training data to a new CSV file\n",
    "train_data.to_csv('./telcocustomerchurn/WA_Fn-UseC_-Telco-Customer-Churn_Train.csv', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upload datasets to Azure ML workspace Datastore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mltable\n",
    "from azure.ai.ml.entities import Data\n",
    "from azure.ai.ml.constants import AssetTypes\n",
    "\n",
    "\n",
    "train_data_paths = [\n",
    "    {'file': './wa_telco_customer_churn_train_data/WA_Fn-UseC_-Telco-Customer-Churn_Train.csv'},\n",
    "]\n",
    "\n",
    "train_table = mltable.from_delimited_files(train_data_paths)\n",
    "train_table.save('./wa_telco_customer_churn_train_data')\n",
    "# Save the training data to a new CSV file\n",
    "train_data.to_csv(train_data_paths[0]['file'], index=False)\n",
    "\n",
    "\n",
    "test_data_paths = [\n",
    "    {'file': './wa_telco_customer_churn_test_data/WA_Fn-UseC_-Telco-Customer-Churn_Test.csv'},\n",
    "]\n",
    "\n",
    "test_table = mltable.from_delimited_files(test_data_paths)\n",
    "test_table.save('./wa_telco_customer_churn_test_data')\n",
    "# Save the generated test data to a new CSV file\n",
    "test_data.to_csv(test_data_paths[0]['file'], index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(data_path, data_asset_name, data_asset_version, asset_type):\n",
    "    data_asset_def = Data(\n",
    "        name=data_asset_name,\n",
    "        version=data_asset_version,\n",
    "        description=data_asset_name,\n",
    "        path=data_path,\n",
    "        type=asset_type,\n",
    "    )\n",
    "    data_asset = None\n",
    "    ## create data asset if it doesn't already exist:\n",
    "    try:\n",
    "        data_asset = ml_client.data.get(name=data_asset_name, version=data_asset_version)\n",
    "        print(\n",
    "            f\"Data asset already exists. Name: {data_asset_def.name}, version: {data_asset_def.version}\"\n",
    "        )\n",
    "    except:\n",
    "        ml_client.data.create_or_update(data_asset_def)\n",
    "        print(f\"Data asset created. Name: {data_asset_def.name}, version: {data_asset_def.version}\")\n",
    "\n",
    "    data_asset = ml_client.data.get(name=data_asset_name, version=data_asset_version)\n",
    "    return data_asset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create training Dataset in MLTABLE format. Automated ML in AML only supports MLTABLE format. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"./wa_telco_customer_churn_train_data\"\n",
    "data_asset_name = \"wa_telco_customer_churn_train_data\"\n",
    "data_asset_version = \"1.5\"\n",
    "training_data_asset =create_dataset(data_path, data_asset_name, data_asset_version, AssetTypes.MLTABLE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create test Dataset in Uri_File format to be used in Scoring."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"./wa_telco_customer_churn_test_data_uri_file/wa_telco_customer_churn_test_data_uri_file.csv\"\n",
    "data_asset_name = \"wa_telco_customer_churn_test_data_uri_file\"\n",
    "data_asset_version = \"1.0\"\n",
    "test_data_asset = create_dataset(data_path, data_asset_name, data_asset_version, AssetTypes.URI_FILE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define AutoML classification job for the Churn Prediction task. \n",
    "The training alogrithms are limited to select few to limit training time. \n",
    "For more information on supported algorithms in AutoML, please see [this](https://learn.microsoft.com/en-us/azure/machine-learning/how-to-configure-auto-train?view=azureml-api-2&tabs=python)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.ml import automl, Input\n",
    "\n",
    "training_data_input = Input(\n",
    "    type=AssetTypes.MLTABLE, path=training_data_asset.path\n",
    ")\n",
    "\n",
    "\n",
    "# configure the classification job\n",
    "classification_job = automl.classification(\n",
    "    compute=\"cpu-cluster\",\n",
    "    experiment_name=\"wa-telco-customer-churn-classification\",\n",
    "    training_data=training_data_input,\n",
    "    target_column_name=\"Churn\",\n",
    "    primary_metric=\"accuracy\",\n",
    "    n_cross_validations=5,\n",
    "    enable_model_explainability=True,\n",
    "    tags={\"my_custom_tag\": \"My custom value\"}\n",
    "    \n",
    ")\n",
    "\n",
    "# Limits are all optional\n",
    "classification_job.set_limits(\n",
    "    timeout_minutes=600, \n",
    "    trial_timeout_minutes=20, \n",
    "    max_trials=5,\n",
    "    enable_early_termination=True,\n",
    ")\n",
    "\n",
    "# Training properties are optional\n",
    "classification_job.set_training(\n",
    "    allowed_training_algorithms=[\"GradientBoosting\", \"DecisionTree\", \"LightGBM\" , \"RandomForest\"], \n",
    "    enable_onnx_compatible_models=True\n",
    ")\n",
    "\n",
    "classification_job.set_featurization(\n",
    "    mode=\"auto\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Submit the AutoML job\n",
    "returned_job = ml_client.jobs.create_or_update(\n",
    "    classification_job\n",
    ")  # submit the job to the backend\n",
    "\n",
    "print(f\"Created job: {returned_job}\")\n",
    "\n",
    "# Get a URL for the status of the job\n",
    "returned_job.services[\"Studio\"].endpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use MLFlow to register the best performing model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "\n",
    "# Obtain the tracking URL from MLClient\n",
    "MLFLOW_TRACKING_URI = ml_client.workspaces.get(\n",
    "    name=ml_client.workspace_name\n",
    ").mlflow_tracking_uri\n",
    "\n",
    "print(MLFLOW_TRACKING_URI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the MLFLOW TRACKING URI\n",
    "\n",
    "mlflow.set_tracking_uri(MLFLOW_TRACKING_URI)\n",
    "\n",
    "print(\"\\nCurrent tracking uri: {}\".format(mlflow.get_tracking_uri()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlflow.tracking.client import MlflowClient\n",
    "from mlflow.artifacts import download_artifacts\n",
    "\n",
    "# Initialize MLFlow client\n",
    "mlflow_client = MlflowClient()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Get the parent run\n",
    "mlflow_parent_run = mlflow_client.get_run(returned_job.name)\n",
    "best_child_run_id = mlflow_parent_run.data.tags['automl_best_child_run_id']\n",
    "# get the best child run\n",
    "best_run = mlflow_client.get_run(best_child_run_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.ml.entities import (\n",
    "    ManagedOnlineEndpoint,\n",
    "    ManagedOnlineDeployment,\n",
    "    Model,\n",
    "    Environment,\n",
    "    CodeConfiguration,\n",
    "    ProbeSettings,\n",
    ")\n",
    "from azure.ai.ml.constants import ModelType\n",
    "\n",
    "model_name = \"wa_telco_customer_churn_model_best\"\n",
    "model = Model(\n",
    "    path=f\"azureml://jobs/{best_run.info.run_id}/outputs/artifacts/outputs/mlflow-model/\",\n",
    "    name=model_name,\n",
    "    description=\"wa_telco_customer_churn_model_best\",\n",
    "    type=AssetTypes.MLFLOW_MODEL,\n",
    ")\n",
    "\n",
    "# for downloaded file\n",
    "# model = Model(path=\"artifact_downloads/outputs/model.pkl\", name=model_name)\n",
    "\n",
    "registered_model = ml_client.models.create_or_update(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's pick the latest version of the model\n",
    "latest_model = max(\n",
    "    [(m.version) for m in ml_client.models.list(name=registered_model.name)]\n",
    ")\n",
    "\n",
    "print(latest_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download AutoML artifacts for scoring later. We will use both local scoring and batch scoring using compute cluster. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Create local folder\n",
    "local_dir = \"./artifact_downloads\"\n",
    "if not os.path.exists(local_dir):\n",
    "    os.mkdir(local_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download run's artifacts/outputs\n",
    "local_path = download_artifacts(\n",
    "    run_id=best_run.info.run_id, artifact_path=\"outputs\", dst_path=local_dir\n",
    ")\n",
    "print(\"Artifacts downloaded in: {}\".format(local_path))\n",
    "print(\"Artifacts: {}\".format(os.listdir(local_path)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "amlsdkv2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
