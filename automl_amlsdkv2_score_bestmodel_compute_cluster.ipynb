{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scoring using the best model locally - Optional"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The training environment in AML compute cluster can be different than the one locally. We need to create a new Conda environment in the repo so that model can be loaded locally. \n",
    "\n",
    "    conda env create -f conda_env.yml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the model file downloaded using automl_amlsdkv2_training.ipynb. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If AML Compute Instance is used for local scoring, then the notebook kernel should be set to Python 3.8 - AzureML\n",
    "\n",
    "If AML Compute Cluster is used for remote scoring, then the notebook kernel should be set to Python 3.10 - SDK v2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Score using Compute Cluster in AML - Optional "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.identity import DefaultAzureCredential, InteractiveBrowserCredential\n",
    "from azure.ai.ml import MLClient\n",
    "try:\n",
    "    credential = DefaultAzureCredential()\n",
    "    # Check if given credential can get token successfully.\n",
    "    credential.get_token(\"https://management.azure.com/.default\")\n",
    "except Exception as ex:\n",
    "    # Fall back to InteractiveBrowserCredential in case DefaultAzureCredential not work\n",
    "    credential = InteractiveBrowserCredential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Provide values for your AML workspace\n",
    "\n",
    "    subscription_id = \"YOUR_SUBSCRIPTION_ID\"\n",
    "    resource_group = \"YOUR_RESOURCE_GROUP\"\n",
    "    workspace = \"YOUR_WORKSPACE_NAME\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ml_client = None\n",
    "try:\n",
    "    ml_client = MLClient.from_config(credential)\n",
    "except Exception as ex:\n",
    "    print(ex)\n",
    "    # Enter details of your Azure Machine Learning workspace\n",
    "    subscription_id = \"f1a8fafd-a8a3-46d8-bb5e-01deb63d275d\"\n",
    "    resource_group = \"aml-rg\"\n",
    "    workspace = \"aml-testws\"\n",
    "    ml_client = MLClient(credential, subscription_id, resource_group, workspace)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the model name created in automl_amlsdkv2_training.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.ml.entities import Model\n",
    "from azure.ai.ml.constants import ModelType\n",
    "\n",
    "model_name = \"wa_telco_customer_churn_model_best\"\n",
    "model_versions = ml_client.models.list(name=model_name)\n",
    "latest_model = max(model_versions, key=lambda x: x.version)\n",
    "latest_model.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.ml import command, Input, Output\n",
    "from azure.ai.ml.constants import AssetTypes, InputOutputModes\n",
    "data_type = AssetTypes.MLTABLE\n",
    "input_mode = InputOutputModes.RO_MOUNT\n",
    "output_mode = InputOutputModes.RW_MOUNT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get reference to test dataset from AML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_asset_name = \"wa_telco_customer_churn_test_data_uri_file\"\n",
    "data_asset_version = \"1.0\"\n",
    "data_asset = ml_client.data.get(name=data_asset_name, version=data_asset_version)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create Input schema for scoring job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#data_path = \"./wa_telco_customer_churn_test_data_uri_file.csv\"\n",
    "inputs = {\n",
    "    \"input_data\": Input(type=AssetTypes.URI_FILE, path=data_asset.path),\n",
    "    \"input_model\": Input(type=AssetTypes.MLFLOW_MODEL, path=latest_model.path)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create Output schema for scoring job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = \"wa-telco-customer-churn-predictions\"\n",
    "dataset_version = \"1.0\"\n",
    "outputs = {\n",
    "    \"output_folder\": Output(\n",
    "        type=AssetTypes.URI_FOLDER,\n",
    "        path=f\"azureml://subscriptions/{ml_client.subscription_id}/resourcegroups/{ml_client.resource_group_name}/workspaces/{ml_client.workspace_name}/datastores/workspaceblobstore/paths/{dataset_path}\",\n",
    "        name = dataset_path,\n",
    "        version = dataset_version\n",
    "    )\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define scoring job using Command component"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the same environment as the model was created in AutoML. \n",
    "    \n",
    "        AzureML-AutoML:142"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please review score.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.ml import command, Input\n",
    "\n",
    "\n",
    "# define the command\n",
    "command_job = command(\n",
    "    code=\"./\",\n",
    "    command=\"python score.py --input_model ${{inputs.input_model}} --input_data ${{inputs.input_data}} --output_folder ${{outputs.output_folder}}\",\n",
    "    experiment_name=\"wa-telco-customer-churn-prediction\",\n",
    "    inputs=inputs,\n",
    "    outputs=outputs,    \n",
    "    environment=\"AzureML-AutoML:142\",\n",
    "    compute=\"cpu-cluster\",\n",
    ")\n",
    "\n",
    "# Submit the command\n",
    "ml_client.jobs.create_or_update(command_job)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please review the results of the Scoring job in Aml Workspace. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "automlscoring",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
