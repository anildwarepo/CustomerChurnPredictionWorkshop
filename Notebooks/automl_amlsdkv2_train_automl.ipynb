{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Customer Churn Prediction using Automated ML in Azure Machine Learning using Azure ML SDK V2\n",
    "\n",
    "This notebook guides users to create an Automl job using AML SDK V2. Once the AutoML job completes, the best performing model is registered in AML registry using MLFLow. \n",
    "\n",
    "\n",
    "This notebook uses [Telco Customer Churn data from IBM Sample Datasets](https://community.ibm.com/community/user/businessanalytics/blogs/steven-macko/2019/07/11/telco-customer-churn-1113).\n",
    "\n",
    "\n",
    "### Pre-requisites\n",
    "* Azure Machine Learning workspace provisioned.\n",
    "* Compute Cluster provisioned in the workspace.\n",
    "* Training Cluster created. Recommend to create training cluster with 3 nodes with each Node have 2 vCPUs. This can reduce the AutoML training time. This notebook takes about 12 minutes to complete the training on a 3 node CPU cluster with Standard_DS11_v2 (2 cores, 14 GB RAM, 28 GB disk). \n",
    "* Recommendation is to use AML compute instance to run the notebook.\n",
    "* The notebook can be run locally but will the following dependencies installed locally:\n",
    " \n",
    "    - python installed - python 3.8+\n",
    "    - conda installed\n",
    "    - Azure ML Python [SDK](https://learn.microsoft.com/en-us/python/api/overview/azure/ai-ml-readme?view=azure-python) and [CLI](https://learn.microsoft.com/en-us/azure/machine-learning/how-to-configure-cli?view=azureml-api-2&tabs=public) v2 installed.\n",
    "    - Install additional dependencies in the conda_env.yml\n",
    "    \n",
    "            conda env create -f conda_env.yml\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "* AML workspace can be configured with Private Endpoint and necessary DNS changes are made as documented [here](https://learn.microsoft.com/en-us/azure/machine-learning/how-to-custom-dns?view=azureml-api-2&tabs=azure-cli). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Login using Azure using az login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.identity import DefaultAzureCredential, InteractiveBrowserCredential\n",
    "from azure.ai.ml import MLClient\n",
    "try:\n",
    "    credential = DefaultAzureCredential()\n",
    "    # Check if given credential can get token successfully.\n",
    "    credential.get_token(\"https://management.azure.com/.default\")\n",
    "except Exception as ex:\n",
    "    # Fall back to InteractiveBrowserCredential in case DefaultAzureCredential not work\n",
    "    credential = InteractiveBrowserCredential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Provide values for your AML workspace\n",
    "\n",
    "    subscription_id = \"YOUR_SUBSCRIPTION_ID\"\n",
    "    resource_group = \"YOUR_RESOURCE_GROUP\"\n",
    "    workspace = \"YOUR_WORKSPACE_NAME\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We could not find config.json in: . or in its parent directories. Please provide the full path to the config file or ensure that config.json exists in the parent directories.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "ml_client = None\n",
    "try:\n",
    "    ml_client = MLClient.from_config(credential)\n",
    "except Exception as ex:\n",
    "    print(ex)\n",
    "    # Enter details of your Azure Machine Learning workspace\n",
    "    subscription_id = \"f1a8fafd-a8a3-46d8-bb5e-01deb63d275d\"\n",
    "    resource_group = \"aml-rg\"\n",
    "    workspace = \"aml-testws\"\n",
    "    ml_client = MLClient(credential, subscription_id, resource_group, workspace)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the Sample Dataset WA_Fn-UseC_-Telco-Customer-Churn.csv and create datasets for Training and Testing. \n",
    "The test dataset is used to create a scoring job using the best performance model. \n",
    "The training and test dataset are created from the same Sample dataset. The test dataset maintains the same class balance as the Original Sample dataset. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Provide your own unique dataset name or use system generated UUID format. Providing your own name would help to locate dataset easily in the AML workspace. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1155c2a891714097b099ade1fee4bddb'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import uuid\n",
    "\n",
    "my_unique_dataset_name = uuid.uuid4().hex # Provide your own unique dataset name\n",
    "my_unique_dataset_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load training data from CSV file\n",
    "training_data = pd.read_csv('.././telcocustomerchurn/WA_Fn-UseC_-Telco-Customer-Churn.csv')\n",
    "\n",
    "# Separate the data into features (X) and labels (y)\n",
    "X = training_data.drop(columns=['Churn'])  # Assuming 'label' is the column containing class labels\n",
    "y = training_data['Churn']\n",
    "\n",
    "# Split the data into training and test sets while maintaining class balance\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
    "\n",
    "# Combine the features and labels for training and test sets\n",
    "train_data = pd.concat([X_train, y_train], axis=1)\n",
    "test_data = pd.concat([X_test, y_test], axis=1)\n",
    "\n",
    "# Save the generated test data to a new CSV file\n",
    "test_data.to_csv(f'.././telcocustomerchurn/{my_unique_dataset_name}-WA_Fn-UseC_-Telco-Customer-Churn_Test.csv', index=False)\n",
    "\n",
    "# Save the training data to a new CSV file\n",
    "train_data.to_csv(f'.././telcocustomerchurn/{my_unique_dataset_name}-WA_Fn-UseC_-Telco-Customer-Churn_Train.csv', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upload datasets to Azure ML workspace Datastore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_path = f'.././telcocustomerchurn/{my_unique_dataset_name}_train/{my_unique_dataset_name}-WA_Fn-UseC_-Telco-Customer-Churn_Train.csv'\n",
    "test_data_path = f'.././telcocustomerchurn/{my_unique_dataset_name}_test/{my_unique_dataset_name}-WA_Fn-UseC_-Telco-Customer-Churn_Test.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mltable\n",
    "from azure.ai.ml.entities import Data\n",
    "from azure.ai.ml.constants import AssetTypes\n",
    "\n",
    "\n",
    "train_data_paths = [\n",
    "    {'file': train_data_path},\n",
    "]\n",
    "\n",
    "train_table = mltable.from_delimited_files(train_data_paths)\n",
    "train_table.save(f'.././telcocustomerchurn/{my_unique_dataset_name}_train')\n",
    "# Save the training data to a new CSV file\n",
    "train_data.to_csv(train_data_paths[0]['file'], index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../telcocustomerchurn/1155c2a891714097b099ade1fee4bddb_test/1155c2a891714097b099ade1fee4bddb-WA_Fn-UseC_-Telco-Customer-Churn_Test.csv'"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "test_data_paths = [\n",
    "    {'file': test_data_path},\n",
    "]\n",
    "\n",
    "\n",
    "outdir = f'.././telcocustomerchurn/{my_unique_dataset_name}_test'\n",
    "if not os.path.exists(outdir):\n",
    "    os.mkdir(outdir)\n",
    "# Save the generated test data to a new CSV file\n",
    "test_data.to_csv(test_data_paths[0]['file'], index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(data_path, data_asset_name, data_asset_version, asset_type):\n",
    "    data_asset_def = Data(\n",
    "        name=data_asset_name,\n",
    "        version=data_asset_version,\n",
    "        description=data_asset_name,\n",
    "        path=data_path,\n",
    "        type=asset_type,\n",
    "    )\n",
    "    data_asset = None\n",
    "    ## create data asset if it doesn't already exist:\n",
    "    try:\n",
    "        data_asset = ml_client.data.get(name=data_asset_name, version=data_asset_version)\n",
    "        print(\n",
    "            f\"Data asset already exists. Name: {data_asset_def.name}, version: {data_asset_def.version}\"\n",
    "        )\n",
    "    except Exception as ex:\n",
    "        ml_client.data.create_or_update(data_asset_def)\n",
    "        print(f\"Data asset created. Name: {data_asset_def.name}, version: {data_asset_def.version}\")\n",
    "\n",
    "    data_asset = ml_client.data.get(name=data_asset_name, version=data_asset_version)\n",
    "    return data_asset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create training Dataset in MLTABLE format. Automated ML in AML only supports MLTABLE format. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data asset already exists. Name: 1155c2a891714097b099ade1fee4bddb-wa_telco_customer_churn_train_data, version: 1.0\n"
     ]
    }
   ],
   "source": [
    "data_path = f'.././telcocustomerchurn/{my_unique_dataset_name}_train'\n",
    "data_asset_name = f\"{my_unique_dataset_name}-wa_telco_customer_churn_train_data\"\n",
    "data_asset_version = \"1.0\"\n",
    "training_data_asset =create_dataset(data_path, data_asset_name, data_asset_version, AssetTypes.MLTABLE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create test Dataset in Uri_File format to be used in Scoring."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading 1155c2a891714097b099ade1fee4bddb-WA_Fn-UseC_-Te... (< 1 MB): 0.00B [00:00, ?B/s] (< 1 MB): 100%|##########| 196k/196k [00:00<00:00, 827kB/s] (< 1 MB): 100%|##########| 196k/196k [00:00<00:00, 774kB/s]\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data asset created. Name: 1155c2a891714097b099ade1fee4bddb-wa_telco_customer_churn_test_data, version: 1.0\n"
     ]
    }
   ],
   "source": [
    "data_path = test_data_path\n",
    "data_asset_name = f\"{my_unique_dataset_name}-wa_telco_customer_churn_test_data\"\n",
    "data_asset_version = \"1.0\"\n",
    "test_data_asset = create_dataset(data_path, data_asset_name, data_asset_version, AssetTypes.URI_FILE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define AutoML classification job for the Churn Prediction task. \n",
    "The training alogrithms are limited to select few to limit training time. \n",
    "For more information on supported algorithms in AutoML, please see [this](https://learn.microsoft.com/en-us/azure/machine-learning/how-to-configure-auto-train?view=azureml-api-2&tabs=python)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.ml import automl, Input\n",
    "\n",
    "training_data_input = Input(\n",
    "    type=AssetTypes.MLTABLE, path=training_data_asset.path\n",
    ")\n",
    "\n",
    "\n",
    "# configure the classification job\n",
    "classification_job = automl.classification(\n",
    "    compute=\"cpu-cluster\",\n",
    "    experiment_name=f\"{my_unique_dataset_name}-wa-telco-customer-churn-classification\",\n",
    "    training_data=training_data_input,\n",
    "    target_column_name=\"Churn\",\n",
    "    primary_metric=\"accuracy\",\n",
    "    n_cross_validations=5,\n",
    "    enable_model_explainability=True,\n",
    "    tags={\"my_custom_tag\": \"My custom value\"}\n",
    "    \n",
    ")\n",
    "\n",
    "# Limits are all optional\n",
    "classification_job.set_limits(\n",
    "    timeout_minutes=600, \n",
    "    trial_timeout_minutes=20, \n",
    "    max_trials=5,\n",
    "    enable_early_termination=True,\n",
    ")\n",
    "\n",
    "# Training properties are optional\n",
    "classification_job.set_training(\n",
    "    allowed_training_algorithms=[\"GradientBoosting\", \"DecisionTree\", \"LightGBM\" , \"RandomForest\"], \n",
    "    enable_onnx_compatible_models=True\n",
    ")\n",
    "\n",
    "classification_job.set_featurization(\n",
    "    mode=\"auto\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created job: compute: azureml:cpu-cluster\n",
      "creation_context:\n",
      "  created_at: '2023-09-08T21:27:32.252811+00:00'\n",
      "  created_by: Anil Dwarakanath\n",
      "  created_by_type: User\n",
      "display_name: jolly_circle_ywmvvvb4dc\n",
      "experiment_name: 1155c2a891714097b099ade1fee4bddb-wa-telco-customer-churn-classification\n",
      "featurization:\n",
      "  enable_dnn_featurization: false\n",
      "  mode: auto\n",
      "id: azureml:/subscriptions/f1a8fafd-a8a3-46d8-bb5e-01deb63d275d/resourceGroups/aml-rg/providers/Microsoft.MachineLearningServices/workspaces/aml-testws/jobs/jolly_circle_ywmvvvb4dc\n",
      "limits:\n",
      "  enable_early_termination: true\n",
      "  max_concurrent_trials: 1\n",
      "  max_cores_per_trial: -1\n",
      "  max_nodes: 1\n",
      "  max_trials: 5\n",
      "  timeout_minutes: 600\n",
      "  trial_timeout_minutes: 20\n",
      "log_verbosity: info\n",
      "n_cross_validations: 5\n",
      "name: jolly_circle_ywmvvvb4dc\n",
      "outputs: {}\n",
      "primary_metric: accuracy\n",
      "properties:\n",
      "  azureml.git.dirty: 'True'\n",
      "  mlflow.source.git.branch: main\n",
      "  mlflow.source.git.commit: 41f032aa5a37018b74add5bcf52d67676731cbc2\n",
      "  mlflow.source.git.repoURL: https://github.com/anildwarepo/CustomerChurnPredictionWorkshop.git\n",
      "resources:\n",
      "  instance_count: 1\n",
      "  shm_size: 2g\n",
      "services:\n",
      "  Studio:\n",
      "    endpoint: https://ml.azure.com/runs/jolly_circle_ywmvvvb4dc?wsid=/subscriptions/f1a8fafd-a8a3-46d8-bb5e-01deb63d275d/resourcegroups/aml-rg/workspaces/aml-testws&tid=7f1290b4-3c39-4277-a63e-c577680a12cf\n",
      "  Tracking:\n",
      "    endpoint: azureml://westus.api.azureml.ms/mlflow/v1.0/subscriptions/f1a8fafd-a8a3-46d8-bb5e-01deb63d275d/resourceGroups/aml-rg/providers/Microsoft.MachineLearningServices/workspaces/aml-testws?\n",
      "status: NotStarted\n",
      "tags:\n",
      "  my_custom_tag: My custom value\n",
      "target_column_name: Churn\n",
      "task: classification\n",
      "training:\n",
      "  allowed_training_algorithms:\n",
      "  - gradient_boosting\n",
      "  - decision_tree\n",
      "  - light_gbm\n",
      "  - random_forest\n",
      "  enable_dnn_training: false\n",
      "  enable_model_explainability: true\n",
      "  enable_onnx_compatible_models: true\n",
      "  enable_stack_ensemble: true\n",
      "  enable_vote_ensemble: true\n",
      "  ensemble_model_download_timeout_minutes: 5\n",
      "  training_mode: auto\n",
      "training_data:\n",
      "  path: azureml://subscriptions/f1a8fafd-a8a3-46d8-bb5e-01deb63d275d/resourcegroups/aml-rg/workspaces/aml-testws/datastores/workspaceblobstore/paths/LocalUpload/831a4210952ed82242598f511b6d750a/1155c2a891714097b099ade1fee4bddb_train/\n",
      "  type: mltable\n",
      "type: automl\n",
      "validation_data:\n",
      "  type: mltable\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'https://ml.azure.com/runs/jolly_circle_ywmvvvb4dc?wsid=/subscriptions/f1a8fafd-a8a3-46d8-bb5e-01deb63d275d/resourcegroups/aml-rg/workspaces/aml-testws&tid=7f1290b4-3c39-4277-a63e-c577680a12cf'"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Submit the AutoML job\n",
    "returned_job = ml_client.jobs.create_or_update(\n",
    "    classification_job\n",
    ")  # submit the job to the backend\n",
    "\n",
    "print(f\"Created job: {returned_job}\")\n",
    "\n",
    "# Get a URL for the status of the job\n",
    "returned_job.services[\"Studio\"].endpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wait till the Automl Job completes before continuing from here. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use MLFlow to register the best performing model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "azureml://74f7aea0-6b0e-4b75-a8e4-001d9a929102.workspace.westus.api.azureml.ms/mlflow/v1.0/subscriptions/f1a8fafd-a8a3-46d8-bb5e-01deb63d275d/resourceGroups/aml-rg/providers/Microsoft.MachineLearningServices/workspaces/aml-testws\n"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "\n",
    "# Obtain the tracking URL from MLClient\n",
    "MLFLOW_TRACKING_URI = ml_client.workspaces.get(\n",
    "    name=ml_client.workspace_name\n",
    ").mlflow_tracking_uri\n",
    "\n",
    "print(MLFLOW_TRACKING_URI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current tracking uri: azureml://74f7aea0-6b0e-4b75-a8e4-001d9a929102.workspace.westus.api.azureml.ms/mlflow/v1.0/subscriptions/f1a8fafd-a8a3-46d8-bb5e-01deb63d275d/resourceGroups/aml-rg/providers/Microsoft.MachineLearningServices/workspaces/aml-testws\n"
     ]
    }
   ],
   "source": [
    "# Set the MLFLOW TRACKING URI\n",
    "\n",
    "mlflow.set_tracking_uri(MLFLOW_TRACKING_URI)\n",
    "\n",
    "print(\"\\nCurrent tracking uri: {}\".format(mlflow.get_tracking_uri()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlflow.tracking.client import MlflowClient\n",
    "from mlflow.artifacts import download_artifacts\n",
    "\n",
    "# Initialize MLFlow client\n",
    "mlflow_client = MlflowClient()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Get the parent run\n",
    "mlflow_parent_run = mlflow_client.get_run(returned_job.name)\n",
    "best_child_run_id = mlflow_parent_run.data.tags['automl_best_child_run_id']\n",
    "# get the best child run\n",
    "best_run = mlflow_client.get_run(best_child_run_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.ml.entities import (\n",
    "    ManagedOnlineEndpoint,\n",
    "    ManagedOnlineDeployment,\n",
    "    Model,\n",
    "    Environment,\n",
    "    CodeConfiguration,\n",
    "    ProbeSettings,\n",
    ")\n",
    "from azure.ai.ml.constants import ModelType\n",
    "\n",
    "model_name = f\"{my_unique_dataset_name}-wa_telco_customer_churn_model_best\"\n",
    "model = Model(\n",
    "    path=f\"azureml://jobs/{best_run.info.run_id}/outputs/artifacts/outputs/mlflow-model/\",\n",
    "    name=model_name,\n",
    "    description=\"wa_telco_customer_churn_model_best\",\n",
    "    type=AssetTypes.MLFLOW_MODEL,\n",
    ")\n",
    "\n",
    "# for downloaded file\n",
    "# model = Model(path=\"artifact_downloads/outputs/model.pkl\", name=model_name)\n",
    "\n",
    "registered_model = ml_client.models.create_or_update(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "# Let's pick the latest version of the model\n",
    "latest_model = max(\n",
    "    [(m.version) for m in ml_client.models.list(name=registered_model.name)]\n",
    ")\n",
    "\n",
    "print(latest_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download AutoML artifacts for scoring later. We will use both local scoring and batch scoring using compute cluster. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Create local folder\n",
    "local_dir = \".././artifact_downloads\"\n",
    "if not os.path.exists(local_dir):\n",
    "    os.mkdir(local_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading artifacts:   0%|          | 0/20 [00:00<?, ?it/s]2023/09/08 14:49:50 INFO mlflow.store.artifact.artifact_repo: The progress bar can be disabled by setting the environment variable MLFLOW_ENABLE_ARTIFACTS_PROGRESS_BAR to false\n",
      "Downloading artifacts: 100%|██████████| 20/20 [00:04<00:00,  4.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Artifacts downloaded in: c:\\source\\repos\\aml-customer-churn-prediction\\artifact_downloads\\outputs\n",
      "Artifacts: ['conda_env_v_1_0_0.yml', 'engineered_feature_names.json', 'env_dependencies.json', 'featurization_summary.json', 'generated_code', 'internal_cross_validated_models.pkl', 'mlflow-model', 'model.onnx', 'model.pkl', 'model_onnx.json', 'pipeline_graph.json', 'run_id.txt', 'scoring_file_pbi_v_1_0_0.py', 'scoring_file_v_1_0_0.py', 'scoring_file_v_2_0_0.py']\n"
     ]
    }
   ],
   "source": [
    "# Download run's artifacts/outputs\n",
    "local_path = download_artifacts(\n",
    "    run_id=best_run.info.run_id, artifact_path=\"outputs\", dst_path=local_dir\n",
    ")\n",
    "print(\"Artifacts downloaded in: {}\".format(local_path))\n",
    "print(\"Artifacts: {}\".format(os.listdir(local_path)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "amlsdkv2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
